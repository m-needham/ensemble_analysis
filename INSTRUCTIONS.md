# Typical Workflow

Updated 3 November 2022

### 1. Create a new project direcotry

**DO NOT EDIT THE FILES IN `./src`**

Instead, in the home directory, run 

```bash
bash create_project.sh PROJECT_NAME
```

To create a custom set of files for analysis.

### 2. Make edits to `submit.sh`

Navigate to your new project directory.

* Ensure PBS submission options are correct
    * `-N` Job name
    * `-A` Account number
    * etc.

* Specify the data frequency

```bash
# Analyze monthly mean output
ENSEMBLE_NAME="month_1"
```

> Note: this string directly corresponds to the name of one of the directories in the particular large ensemble's data path. For example, `/glade/campaign/cgd/cesm/CESM2-LE/timeseries/atm/proc/tseries/` has four directories: `day_1`  `hour_3`  `hour_6`  `month_1`

* Specify the ensemble to analyze

```bash
# Analyze the CESM2 large ensemble
ENSEMBLE_NAME="CESM2-LE"
```

> Note: the function `get_ensemble_data_path` in `_analysis_functions.py` allows the user to specify additional ensembles. However, this will require updating the file `_generate_casenames.py` to account for a different naming convention.

* Specify where output files should be stored

```bash
# Store in a custom directory in the user's work directory
SAVE_PATH="/glade/work/$USER/ensemble_analysis/"
```

> Note: If the specified directory does not exist, the script will attempt to create it. However, if one of the parent directories does not exist, the script will throw an error. It is recommended to ensure the desired `SAVE_PATH` exists prior to running the script with the quick command `$ mkdir desired_save_path`

### 3. Make edits to `user_functions.py`

1. Update `custom_variable_list` to include the desired variables to import and pass to the custom analysis function

2. Specify `custom_preprocess_function` to perform the desired data preprocessing for a single ensemble member. All of the variables specified in `custom_variable_list` will be inherited in the dataset `dset_ens` for use here. Examples of preprocessing include:
    * Interpolating from model hybrid coordinates to pressure coordinates
    * Spatial or temporal resampling
    * Spatial or temporal subsetting ([Recommended by xarray to occur early in the pipeline](https://docs.xarray.dev/en/stable/user-guide/dask.html#optimization-tips))


3. Specify `custom_analysis_function` to perform the desired computations for a single ensemble member. All of the variables after preprocessing will automatically be available here.

### 4. Run the script

The entire application can be run on [Casper](https://arc.ucar.edu/knowledge_base/70549550) with the command

```bash
qsub submit.sh
```

This will submit a PBS job to the casper queue. The script can instead be run on a login node (good for testing) with the command

```bash
bash submit.sh
```

although the performance of the script may appear to suffer because the PBS submission to initialize the dask cluster (see appendix below for more details about parallelism with dask) may languish in the job queue.

### Testing mode

It is a good idea to test that the custom analysis function works as expected. To do so, edit the `submit.sh` script to set the following testing flags to `"TRUE"` (by default, they are both set to `"FALSE"`.

```bash
# ================================ TESTING MODE ================================
TESTING_MODE_N_ENS="FALSE"
TESTING_MODE_N_TIME="FALSE"
```

* If `TESTING_MODE_N_ENS="TRUE"`, the script will be run with analysis applied only to the first two ensemble members

* If `TESTING_MODE_N_TIME="FALSE"`, the script will be run with analysis only applied to the first ten timesteps

> NOTE: `TESTING_MODE_N_ENS` must be set to "TRUE" in order for `TESTING_MODE_N_TIME` to be utilized. The following combination:
`TESTING_MODE_N_ENS="FALSE"`, `TESTING_MODE_N_TIME="TRUE"`
will have no effect

## Appendix: Parallel Computation

Looping over ensemble members and performing independent calculations on each is an [embarressingly parallel](https://en.wikipedia.org/wiki/Embarrassingly_parallel) computational task. This script is written to seamlessly take python analysis code and execute it in parallel

Parallel computation is accomplished with the python package [dask](https://docs.dask.org/en/stable/), particularly through the use of the [dask delayed](https://docs.dask.org/en/stable/delayed.html) interface. This wraps standard python functions to generate task graphs of the computation to be evaluated lazily rather than actually evaluating the computations eagerly in real-time.

The script also gives the user the opportunity to view the dask diagnostic dashboard. Log files generated by the script include instructions for viewing the dashboard for both local jobs and jobs submitted to a PBS queue.

> Currently only support for PBS systems are implemented, but systems using other job queues (e.g., SLURM) could be impemented using [dask-jobqueue](https://jobqueue.dask.org/en/latest/).
